{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc-2MCEt5HKJ",
        "outputId": "f2872bf9-1275-4828-bc5d-a8711df542c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0eG0tnYp9qZ"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1z2clae-zgP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import os.path as op\n",
        "from pathlib   import Path\n",
        "from glob      import glob\n",
        "from tqdm      import tqdm\n",
        "from datetime  import datetime\n",
        "import random\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfW6t3FPzgF0",
        "outputId": "e5df09ce-5d94-4726-cc00-b756e0620901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_tracks = 16080\n",
            "5 Example Track IDs = ['lab_0_0', 'lab_0_1', 'lab_0_2', 'lab_0_3', 'lab_0_4']\n",
            "Per-track keys = dict_keys(['txy', 'label'])\n",
            "Coordinate array = \n",
            "[[  1.    184.166 463.817]\n",
            " [  2.    183.941 463.692]\n",
            " [  3.    183.716 463.567]\n",
            " ...\n",
            " [299.    146.777 448.634]\n",
            " [300.    146.795 448.518]\n",
            " [301.    146.813 448.402]]\n",
            "Label = 0\n"
          ]
        }
      ],
      "source": [
        "###################################################\n",
        "# !!! Remember to look at data_dictionary.txt !!! #\n",
        "###################################################\n",
        "\n",
        "\n",
        "# Set your target file here #######################\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CS155Proj1/train.json\", 'r') as f:\n",
        "    track_data = json.load(f)\n",
        "\n",
        "###################################################\n",
        "\n",
        "\n",
        "# How many tracks are there?\n",
        "print(f\"n_tracks = {len(track_data.keys())}\")\n",
        "\n",
        "# What do the track Unique IDs (UIDs) look like?\n",
        "track_uids = list(track_data.keys())\n",
        "print(f\"5 Example Track IDs = {track_uids[:5]}\")\n",
        "\n",
        "# What fields are avaiable for each track?\n",
        "example_uid = track_uids[0]\n",
        "print(f\"Per-track keys = {track_data[example_uid].keys()}\")\n",
        "\n",
        "# What do the (t, x, y) track coordinates look like?\n",
        "example_coords = track_data[track_uids[0]]['txy']\n",
        "example_coords = np.array(example_coords)\n",
        "np.set_printoptions(threshold=10)\n",
        "print(f\"Coordinate array = \\n{example_coords}\")\n",
        "\n",
        "# What does the label look like?\n",
        "example_label = track_data[track_uids[0]]['label']\n",
        "print(f\"Label = {example_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzApRWS58oXW",
        "outputId": "f0f0f52e-0afe-4d90-edf6-e665421e38bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(track_data.items())[0][1]['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSjkP-I9ql6R"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoeCqz4WCkQU"
      },
      "outputs": [],
      "source": [
        "# data augmentation\n",
        "\n",
        "def rotate(coords, angle):\n",
        "    rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
        "    return coords @ rotation_matrix.T\n",
        "\n",
        "def stride_time(coords, factor):\n",
        "    assert factor == int(factor)\n",
        "    factor = int(factor)\n",
        "    return coords[0::factor, :]\n",
        "\n",
        "def stretch_space(coords, factor):\n",
        "    return coords * factor\n",
        "\n",
        "def flip_time(coords):\n",
        "    return np.flip(coords, axis=0) - coords[-1, :] + coords[0, :]  # start at same point\n",
        "\n",
        "def flip_space(coords):\n",
        "    return np.hstack([-coords[:,0:1], coords[:,1:2]])  # flip over y axis (negate x coordinate)\n",
        "\n",
        "def augment(coords, rotate_angles=(), stride_time_factors=(), stretch_space_factors=(), flip_t=False, flip_s=False):\n",
        "    # if isinstance(coords, np.array):\n",
        "        # coords = [coords]\n",
        "\n",
        "    aug_list = coords\n",
        "\n",
        "    new_samples = []\n",
        "    for angle in rotate_angles:\n",
        "        new_samples += [rotate(c, angle) for c in aug_list]\n",
        "    aug_list += new_samples\n",
        "\n",
        "    new_samples = []\n",
        "    for factor in stride_time_factors:\n",
        "        new_samples += [stride_time(c, factor) for c in aug_list]\n",
        "    aug_list += new_samples\n",
        "\n",
        "    new_samples = []\n",
        "    for factor in stretch_space_factors:\n",
        "        new_samples += [stretch_space(c, factor) for c in aug_list]\n",
        "    aug_list += new_samples\n",
        "\n",
        "    new_samples = []\n",
        "    if flip_t:\n",
        "        new_samples += [flip_time(c) for c in aug_list]\n",
        "    aug_list += new_samples\n",
        "\n",
        "    new_samples = []\n",
        "    if flip_s:\n",
        "        new_samples += [flip_space(c) for c in aug_list]\n",
        "    aug_list += new_samples\n",
        "\n",
        "    return [x.astype(np.float32) for x in aug_list]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG0deV8j0c-E"
      },
      "outputs": [],
      "source": [
        "class CnnDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, test=False, crop_size=50, aug=True):\n",
        "        # `data` is a list of dicts, each dict contains id, txy, and label\n",
        "\n",
        "        self.test = test\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "        self.data = data\n",
        "        self.id_to_crop_ids = {}\n",
        "\n",
        "        self.rotate_angles = np.linspace(0, 2*np.pi, )\n",
        "\n",
        "        cropped_data = []\n",
        "        for ii, x in enumerate(data):\n",
        "            txy = x['txy']\n",
        "            label = x['label']\n",
        "            track_id = x['id']\n",
        "\n",
        "            if label == 1 or label is None:\n",
        "                stride = 10\n",
        "            else:\n",
        "                stride = 30\n",
        "\n",
        "            if len(txy) < self.crop_size:\n",
        "                # start at 0\n",
        "                txy = txy - txy[0, :]\n",
        "\n",
        "                reps = int(self.crop_size / len(txy)) + 1 # guaranteed to be larger than necessary\n",
        "                copies = [txy]\n",
        "                for i in range(1, reps):\n",
        "                  copies += [txy + copies[i-1][-1,:]]\n",
        "                txy = np.vstack(copies)\n",
        "                txy = txy[:self.crop_size, :]\n",
        "\n",
        "                txys = [txy]\n",
        "\n",
        "            else:\n",
        "                crops = int((len(txy)-self.crop_size)/stride) + 1\n",
        "                start_idxs = np.round(np.linspace(0, len(txy) - self.crop_size, crops)).astype(int)\n",
        "                # self.id_to_crop_ids[ii] = []\n",
        "                txys = []\n",
        "                for start_idx in start_idxs:\n",
        "                    # start at 0\n",
        "                    new_txy = txy[start_idx:start_idx+self.crop_size, :]\n",
        "                    new_txy = new_txy - new_txy[0, :]\n",
        "                    txys += [new_txy]\n",
        "                    # self.id_to_crop_ids[ii] += [len(cropped_data)-1]\n",
        "\n",
        "\n",
        "            if aug:\n",
        "                aug_list = augment(txys,\n",
        "                    rotate_angles=np.linspace(0, 2*np.pi, 13)[1:-1] + np.random.normal(0, np.pi/12, 11),\n",
        "                    # stride_time_factors=[2],\n",
        "                    stretch_space_factors=np.array([0.5, 0.75, 1.25, 1.5]) + np.random.uniform(-0.1, 0.1, 4),\n",
        "                    flip_t=True,\n",
        "                    flip_s=True,\n",
        "                )\n",
        "            else:\n",
        "                aug_list = txys\n",
        "\n",
        "            self.id_to_crop_ids[ii] = []\n",
        "            for aug_txy in aug_list:\n",
        "                cropped_data += [{'id': track_id, 'txy': aug_txy, 'label': label}]\n",
        "                self.id_to_crop_ids[ii] += [len(cropped_data)-1]\n",
        "        self.cropped_data = cropped_data\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.test:\n",
        "            return len(self.data)\n",
        "        else:\n",
        "            return len(self.cropped_data)\n",
        "    def __getitem__(self, idx):\n",
        "        if idx < 0 or idx >= len(self):\n",
        "            # print(idx, \" raising indexerror\")\n",
        "            raise IndexError()\n",
        "\n",
        "        if self.test:\n",
        "            crops = [self.cropped_data[j] for j in self.id_to_crop_ids[idx]]\n",
        "            ret = self.data[idx].copy()\n",
        "            if ret['label'] is None:\n",
        "                ret = {k: v for k, v in ret.items() if k != 'label'}\n",
        "            ret['txy'] = crops\n",
        "            return ret\n",
        "        else:\n",
        "            if self.cropped_data[idx]['label'] is None:\n",
        "                return {k: v for k, v in self.cropped_data[idx].items() if k != 'label'}\n",
        "            else:\n",
        "                return self.cropped_data[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtGRY4OFJIxE"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/CS155Proj1/train.json\"\n",
        "with open(path, 'r') as f:\n",
        "  TRACK_DATA = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWelAnPF5zoE"
      },
      "outputs": [],
      "source": [
        "lab_data = [{'id': k, 'txy': np.array(v['txy'], dtype=np.float32)[:,1:], 'label': v['label']} for (k, v) in TRACK_DATA.items() if k.startswith('lab')]  # TODO\n",
        "\n",
        "# random.shuffle(lab_data)\n",
        "lab_data = sorted(lab_data, key=lambda x: x['id'])\n",
        "trn_vid_nums = range(0, 16)\n",
        "val_vid_nums = range(16, 19)\n",
        "trn_data = [x for x in lab_data if int(x['id'].split('_')[1]) in trn_vid_nums]\n",
        "val_data = [x for x in lab_data if int(x['id'].split('_')[1]) in val_vid_nums]\n",
        "\n",
        "trn_set = CnnDataset(trn_data, test=False, aug=True)\n",
        "val_set = CnnDataset(val_data, test=True, aug=True)\n",
        "trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS0REC1m-jSd",
        "outputId": "aee28726-566b-48f4-85e0-c51f67b7b4f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(550320, 86160)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(trn_set), len(val_set.cropped_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaSgIMqmqo5B"
      },
      "source": [
        "#Model and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7Plh2mT6LGQ"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.activation import Sigmoid\n",
        "model = nn.Sequential(\n",
        "  nn.Conv1d(in_channels=2, out_channels=10, kernel_size=5),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm1d(10),\n",
        "  nn.Conv1d(in_channels=10, out_channels=10, kernel_size=5),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm1d(10),\n",
        "\n",
        "  nn.MaxPool1d(2),\n",
        "\n",
        "\n",
        "  nn.Conv1d(in_channels=10, out_channels=10, kernel_size=5),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm1d(10),\n",
        "  nn.Conv1d(in_channels=10, out_channels=10, kernel_size=5),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm1d(10),\n",
        "\n",
        "  nn.MaxPool1d(2),\n",
        "\n",
        "  nn.Flatten(),\n",
        "  nn.Linear(60, 40),\n",
        "  nn.ReLU(),\n",
        "  nn.Linear(40, 1),\n",
        "\n",
        "  nn.Sigmoid(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTShIlVtXzZD"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, eval_set, eval_loader, is_test, thres=0.5, eval_every=1, raw_wts=False):\n",
        "\n",
        "    old_is_test = eval_set.test\n",
        "    eval_set.test = is_test\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "\n",
        "    if is_test:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for i in range(0, len(eval_set), eval_every):\n",
        "                sample = eval_set[i]\n",
        "            # for i, sample in enumerate(eval_set):\n",
        "                crop_predicted = []\n",
        "                for crop in sample['txy']:\n",
        "                    output = model(torch.Tensor(crop['txy'][None,:,:].swapaxes(1,2)))\n",
        "                    if raw_wts:\n",
        "                        crop_predicted += [output.data[:,0]]\n",
        "                    else:\n",
        "                        crop_predicted += [1*(output.data > thres)[:,0]]\n",
        "\n",
        "                if raw_wts:\n",
        "                    pred = 1 if sum(crop_predicted) > len(crop_predicted) * thres else 0\n",
        "                else:\n",
        "                    pred = 1 if sum(crop_predicted) > len(crop_predicted) / 2 else 0\n",
        "\n",
        "                if (pred == sample['label']):\n",
        "                    correct += 1\n",
        "                    if sample['label'] == 1:\n",
        "                        tp += 1\n",
        "                    else:\n",
        "                        tn += 1\n",
        "                else:\n",
        "                    if sample['label'] == 1:  # pred = 0 so false negative\n",
        "                        fn += 1\n",
        "                    else:\n",
        "                        fp += 1\n",
        "\n",
        "                total += 1\n",
        "                # predictions += [[sample['id'], pred]]\n",
        "\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for i in range(0, len(eval_loader), eval_every):\n",
        "                sample = eval_set[i]\n",
        "            # for i, sample in enumerate(eval_loader):\n",
        "                # forward pass\n",
        "                output = model(sample['txy'].swapaxes(1,2))\n",
        "                # find accuracy\n",
        "                predicted = 1*(output.data > thres)[:,0]\n",
        "                total += sample['label'].size(0)\n",
        "                correct += (predicted == sample['label']).sum().item()\n",
        "                tp += ((predicted == sample['label'])*(predicted == 1)).sum().item()\n",
        "                tn += ((predicted == sample['label'])*(predicted == 0)).sum().item()\n",
        "                fp += ((predicted != sample['label'])*(predicted == 1)).sum().item()\n",
        "                fn += ((predicted != sample['label'])*(predicted == 0)).sum().item()\n",
        "                # find loss\n",
        "                # loss = criterion(output[:,0], sample['label'].to(dtype=torch.float32))\n",
        "                # validation_loss_history[epoch] += loss.item()\n",
        "            # validation_loss_history[epoch] /= len(eval_loader)\n",
        "\n",
        "    acc = correct / total\n",
        "    prc = tp / (tp + fp)\n",
        "    rec = tp / (tp + fn)\n",
        "    f2 = 5 * prc * rec / (4*prc + rec)\n",
        "\n",
        "    eval_set.test = old_is_test\n",
        "\n",
        "    return acc, prc, rec, f2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkrU3SFmCsZ1",
        "outputId": "22309135-96b7-409e-992c-53c3144506fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2:\tloss: 0.2970, acc: 0.8649, val consensus acc: 0.9375\n",
            "Epoch 2/2:\tloss: 0.2505, acc: 0.8866, val consensus acc: 0.9375\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)\n",
        "\n",
        "n_epochs = 2\n",
        "\n",
        "# store metrics\n",
        "training_accuracy_history = np.zeros([n_epochs, 1])\n",
        "training_loss_history = np.zeros([n_epochs, 1])\n",
        "validation_accuracy_history = np.zeros([n_epochs, 1])\n",
        "validation_loss_history = np.zeros([n_epochs, 1])\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "    # train\n",
        "    model.train()\n",
        "    trn_set.test=False\n",
        "    for i, sample in enumerate(trn_loader):\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass\n",
        "        output = model(sample['txy'].swapaxes(1,2))\n",
        "        # calculate categorical cross entropy loss\n",
        "        loss = criterion(output[:,0], sample['label'].to(dtype=torch.float32))\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # track training accuracy\n",
        "        # _, predicted = torch.max(output.data, 1)\n",
        "        predicted = 1*(output.data > 0.5)[:,0]\n",
        "\n",
        "        train_total += sample['label'].size(0)\n",
        "        train_correct += (predicted == sample['label']).sum().item()\n",
        "        # track training loss\n",
        "        training_loss_history[epoch] += loss.item()\n",
        "        # progress update after 180 batches (~1/10 epoch for batch size 32)\n",
        "    training_loss_history[epoch] /= len(trn_loader)\n",
        "    training_accuracy_history[epoch] = train_correct / train_total\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}:\\tloss: {training_loss_history[epoch,0]:0.4f}, acc: {training_accuracy_history[epoch,0]:0.4f}',end='')\n",
        "\n",
        "        acc, prc, rec, f2 = evaluate(model, val_set, val_loader, is_test=True)\n",
        "        print(f', val consensus acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')\n",
        "        acc, prc, rec, f2 = evaluate(model, val_set, val_loader, is_test=False)\n",
        "        print(f', val acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHajccgbtP3a"
      },
      "source": [
        "#Final validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ks5o0eblML",
        "outputId": "09124b3c-3b89-444c-ce04-6343b6c9b57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consensus acc 0.8919 prc 0.7143 rec 1.0000 f2 0.9259"
          ]
        }
      ],
      "source": [
        "acc, prc, rec, f2 = evaluate(model, trn_set, trn_loader, is_test=True, thres=0.2, eval_every=10)\n",
        "print(f'consensus acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')\n",
        "# acc, prc, rec, f2 = evaluate(model, val_set, val_loader, is_test=False, thres=0.5)\n",
        "# print(f', val acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDJOiK12dchK",
        "outputId": "7ebfce9f-52ac-47a8-d8ee-f9cbb5d6760f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consensus acc 0.9730 prc 0.9091 rec 1.0000 f2 0.9804"
          ]
        }
      ],
      "source": [
        "acc, prc, rec, f2 = evaluate(model, trn_set, trn_loader, is_test=True, thres=0.35, eval_every=10)\n",
        "print(f'consensus acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY_HtbZSd3xi",
        "outputId": "1a5a2e12-6467-40d9-a08d-a526c1122336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consensus acc 0.9412 prc 0.9286 rec 0.9286 f2 0.9286"
          ]
        }
      ],
      "source": [
        "acc, prc, rec, f2 = evaluate(model, trn_set, trn_loader, is_test=True, thres=0.35, eval_every=11)\n",
        "print(f'consensus acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuZnzvxUfB7c",
        "outputId": "7411b411-30f8-4395-c44c-9a62071e4f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consensus acc 0.9412 prc 0.9286 rec 0.9286 f2 0.9286"
          ]
        }
      ],
      "source": [
        "acc, prc, rec, f2 = evaluate(model, trn_set, trn_loader, is_test=True, thres=0.35, eval_every=11, raw_wts=True)\n",
        "print(f'consensus acc {acc:0.4f} prc {prc:0.4f} rec {rec:0.4f} f2 {f2:0.4f}', end='')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__VI_V8cdYuW"
      },
      "outputs": [],
      "source": [
        "for tt in [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MiQrgkq7j1R",
        "outputId": "8f0f336e-78e6-4788-ba3d-2437c5b9df57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ", val loss: 0.5921, val acc: 0.8075\n",
            ", val acc: 0.9375\n"
          ]
        }
      ],
      "source": [
        "# validate\n",
        "val_total = 0\n",
        "val_correct = 0\n",
        "val_set.test = False\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, sample in enumerate(val_loader):\n",
        "        # forward pass\n",
        "        output = model(sample['txy'].swapaxes(1,2))\n",
        "        # find accuracy\n",
        "        # _, predicted = torch.max(output.data, 1)\n",
        "        predicted = 1*(output.data > 0.5)[:,0]\n",
        "        val_total += sample['label'].size(0)\n",
        "        val_correct += (predicted == sample['label']).sum().item()\n",
        "        # find loss\n",
        "        loss = criterion(output[:,0], sample['label'].to(dtype=torch.float32))\n",
        "        validation_loss_history[epoch] += loss.item()\n",
        "    validation_loss_history[epoch] /= len(val_loader)\n",
        "    validation_accuracy_history[epoch] = val_correct / val_total\n",
        "print(f', val loss: {validation_loss_history[epoch,0]:0.4f}, val acc: {validation_accuracy_history[epoch,0]:0.4f}')\n",
        "\n",
        "\n",
        "# validate 2\n",
        "\n",
        "# predictions = []\n",
        "val_set.test = True\n",
        "val_total = 0\n",
        "val_correct = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, sample in enumerate(val_set):\n",
        "        crop_predicted = []\n",
        "        for crop in sample['txy']:\n",
        "          output = model(torch.Tensor(crop['txy'][None,:,:].swapaxes(1,2)))\n",
        "          crop_predicted += [1*(output.data > 0.5)[:,0]]\n",
        "        pred = 1 if sum(crop_predicted) > len(crop_predicted) / 2 else 0\n",
        "        if (pred == sample['label']):\n",
        "          val_correct += 1\n",
        "        val_total += 1\n",
        "        # predictions += [[sample['id'], pred]]\n",
        "print(f', consensus val acc: {val_correct/val_total:0.4f}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1ZjaC6COLoE",
        "outputId": "3bfc9639-a03f-4591-e604-9fa649032336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ", wtd consensus val acc: 0.9375\n"
          ]
        }
      ],
      "source": [
        "val_set.test = True\n",
        "val_total = 0\n",
        "val_correct = 0\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, sample in enumerate(val_set):\n",
        "        crop_predicted = []\n",
        "        for crop in sample['txy']:\n",
        "          output = model(torch.Tensor(crop['txy'][None,:,:].swapaxes(1,2)))\n",
        "          crop_predicted += [output.data[:,0]]\n",
        "        pred = 1 if sum(crop_predicted) > len(crop_predicted) / 2 else 0\n",
        "        if (pred == sample['label']):\n",
        "          val_correct += 1\n",
        "        val_total += 1\n",
        "        # predictions += [[sample['id'], pred]]\n",
        "print(f', wtd consensus val acc: {val_correct/val_total:0.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f7j2HlosjP_"
      },
      "source": [
        "#Generate test predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWrdxq6y15-f"
      },
      "outputs": [],
      "source": [
        "testpath = \"/content/drive/MyDrive/CS155Proj1/test.json\"\n",
        "with open(testpath, 'r') as f:\n",
        "  test_data = json.load(f)\n",
        "test_data = [{'id': k, 'txy': np.array(v['txy'], dtype=np.float32)[:,1:], 'label': v['label']} for (k, v) in test_data.items()]\n",
        "\n",
        "tst_set = CnnDataset(test_data, test=True, aug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD01Tc5H2N1x",
        "outputId": "7727769c-8525-4c6c-d4bc-530c97f95093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|                    |\n",
            " *******************"
          ]
        }
      ],
      "source": [
        "# submission\n",
        "thres=0.15\n",
        "raw_wts=True\n",
        "print_update_every=20\n",
        "print('|'+' '*print_update_every+'|')\n",
        "print(' ', end='')\n",
        "\n",
        "\n",
        "predictions = [['UID', 'label']]\n",
        "outputs = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, sample in enumerate(tst_set):\n",
        "        crop_predicted = []\n",
        "        for crop in sample['txy']:\n",
        "          output = model(torch.Tensor(crop['txy'][None,:,:].swapaxes(1,2)))\n",
        "          if raw_wts:\n",
        "            crop_predicted += [output.data[:,0]]\n",
        "          else:\n",
        "            crop_predicted += [1*(output.data > thres)[:,0]]\n",
        "\n",
        "        if raw_wts:\n",
        "          pred = 1 if sum(crop_predicted) > len(crop_predicted) * thres else 0\n",
        "        else:\n",
        "          pred = 1 if sum(crop_predicted) > len(crop_predicted) / 2 else 0\n",
        "        predictions += [[sample['id'], pred]]\n",
        "        outputs += [[sample['id'], float(sum(crop_predicted))/len(crop_predicted)]]\n",
        "\n",
        "\n",
        "        if i in [int(temp) for temp in np.round(np.linspace(-1, len(tst_set)-1, print_update_every+1))]:\n",
        "            print('*', end='')\n",
        "\n",
        "        # predictions += [np.array([sample['id'], predicted.numpy()], dtype=str).T]\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "outputs = np.array(outputs)\n",
        "np.savetxt('/content/drive/MyDrive/CS155Proj1/cnn_submission_4.csv', predictions, delimiter=',', fmt='%s')\n",
        "np.savetxt('/content/drive/MyDrive/CS155Proj1/cnn_submission_4_outputs.csv', outputs, delimiter=',', fmt='%s')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "m0eG0tnYp9qZ",
        "PTa7ustQ6dG2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
